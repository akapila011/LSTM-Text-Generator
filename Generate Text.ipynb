{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_path = \"dataset/wows-script.txt\"  # path to text corpus used. Should be the same as the one the model was trained on\n",
    "weights_path = \"checkpoints/weights-imporvement-11-2.4104.hdf5\"  # path to weights to load the model\n",
    "seed_length = 100  # number of characters to start off with from the corpus\n",
    "generate_length = 1000 # number of characters to generate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset (text) and clean/format it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text has 128743 characters\n",
      "Vocabulary has 52 unique characters\n"
     ]
    }
   ],
   "source": [
    "with open(text_path, \"r\") as f:\n",
    "    raw_text = f.read().lower()\n",
    "\n",
    "characters = sorted(list(set(raw_text))) # sorted list of unique chars\n",
    "char_to_int = dict((c, i) for i, c in enumerate(characters))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(characters))\n",
    "\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(characters)\n",
    "\n",
    "print(\"Text has {} characters\".format(n_chars))\n",
    "print(\"Vocabulary has {} unique characters\".format(n_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patterns 128643\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "data_x = []\n",
    "data_y = []\n",
    "for i in range(0, (len(raw_text)-seq_length), 1):\n",
    "    seq_in = raw_text[i:i+seq_length] # x\n",
    "    seq_out = raw_text[i+seq_length]  # y\n",
    "    data_x.append([char_to_int[char] for char in seq_in])\n",
    "    data_y.append(char_to_int[seq_out])\n",
    "n_patterns = len(data_x)\n",
    "print(\"Total patterns {}\".format(n_patterns))  \n",
    "X = np.reshape(data_x, (n_patterns, seq_length, 1)) # reshape to  [samples, time steps, features]\n",
    "X = X / float(len(char_to_int))  # normalize values\n",
    "y = np_utils.to_categorical(data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the same network arhcitecture\n",
    "\n",
    "and then load the weights from training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model, must be same architecture as the one trained on\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "# load weights\n",
    "model.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: \n",
      "\" 't let him do that.\n",
      "- okay.\n",
      "- 'cause that would make it real.\n",
      "- right.\n",
      "no. what do you do?\n",
      "you get a \"\n"
     ]
    }
   ],
   "source": [
    "# random seed\n",
    "start = np.random.randint(0, len(data_x)-1)\n",
    "pattern = data_x[start]\n",
    "print(\"Seed: \")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet to toeet t\n",
      "--------\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "# Generate characters\n",
    "for i in range(generate_length):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\n--------\\nFinished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
